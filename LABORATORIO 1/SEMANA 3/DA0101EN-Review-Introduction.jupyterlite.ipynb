{"cells":[{"cell_type":"markdown","metadata":{"id":"AM2jWtfAr8Md"},"source":["<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n","</center>\n","\n","# Introduction  Notebook\n","\n","Estimated time needed: **10** minutes\n","\n","## Objectives\n","\n","After completing this lab you will be able to:\n","\n","*   Acquire data in various ways\n","*   Obtain insights from data with Pandas library\n"]},{"cell_type":"markdown","metadata":{"id":"3ZUV0yzor8Mj"},"source":["<h2>Table of Contents</h2>\n","\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","<ol>\n","    <li><a href=\"https://#data_acquisition\">Data Acquisition</a>\n","    <li><a href=\"https://#basic_insight\">Basic Insight of Dataset</a></li>\n","</ol>\n","\n","</div>\n","<hr>\n"]},{"cell_type":"markdown","metadata":{"id":"0nakRp8-r8Mk"},"source":["<h1 id=\"data_acquisition\">Data Acquisition</h1>\n","<p>\n","There are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n","\n","In this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n","\n","In our case, the Automobile Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n","\n","<ul>\n","    <li>Data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a></li>\n","    <li>Data type: csv</li>\n","</ul>\n","The Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n","</p>\n"]},{"cell_type":"markdown","metadata":{"id":"6RR3Vsq2r8Ml"},"source":["you are running the lab in your  browser, so we will install the libraries using `piplite`\n"]},{"cell_type":"code","source":["!apt-get -qq install -y libfluidsynth1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXteshq2u6qc","executionInfo":{"status":"ok","timestamp":1677163483512,"user_tz":300,"elapsed":2602,"user":{"displayName":"Daniela Rios Gonzalez","userId":"13665339571976127570"}},"outputId":"3574bced-b84e-417f-abce-b29dc3f18386"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["E: Package 'libfluidsynth1' has no installation candidate\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"mjctnzfar8Ml","executionInfo":{"status":"error","timestamp":1677163491498,"user_tz":300,"elapsed":3679,"user":{"displayName":"Daniela Rios Gonzalez","userId":"13665339571976127570"}},"outputId":"e175877d-e30f-4b65-f8ba-746a093d297d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.8/dist-packages (0.11.7)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from matplotlib-venn) (1.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from matplotlib-venn) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from matplotlib-venn) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->matplotlib-venn) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->matplotlib-venn) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->matplotlib-venn) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->matplotlib-venn) (1.15.0)\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-b9e32867ca45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#you are running the lab in your  browser, so we will install the libraries using ``piplite``\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install matplotlib-venn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpiplite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmicropip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mpiplite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pandas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'piplite'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#you are running the lab in your  browser, so we will install the libraries using ``piplite``\n","!pip install matplotlib-venn\n","import piplite\n","import micropip\n","await piplite.install(['pandas'])\n","await piplite.install(['matplotlib'])\n","await piplite.install(['scipy'])\n","await piplite.install(['seaborn'])\n","await micropip.install(['ipywidgets'],keep_going=True)\n","await micropip.install(['tqdm'],keep_going=True)"]},{"cell_type":"markdown","metadata":{"id":"Jg1pbQTtr8Mn"},"source":["If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BAkCXjHOr8Mn","executionInfo":{"status":"ok","timestamp":1677163423141,"user_tz":300,"elapsed":288,"user":{"displayName":"Daniela Rios Gonzalez","userId":"13665339571976127570"}}},"outputs":[],"source":["#install specific version of libraries used in  lab\n","#! mamba install pandas==1.3.3  -y\n","#! mamba install numpy=1.21.2 -y"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"sARiO_qBr8Mo","executionInfo":{"status":"ok","timestamp":1677163425729,"user_tz":300,"elapsed":552,"user":{"displayName":"Daniela Rios Gonzalez","userId":"13665339571976127570"}}},"outputs":[],"source":["# import pandas library\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"Q2mj9jYRr8Mo"},"source":["This function will download the dataset into your browser\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"T9wYeofPr8Mp","executionInfo":{"status":"error","timestamp":1677163428998,"user_tz":300,"elapsed":612,"user":{"displayName":"Daniela Rios Gonzalez","userId":"13665339571976127570"}},"outputId":"bc3058c1-0f20-41cb-8e1f-e2127ce7c2ad"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f3c7fe8cb9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#This function will download the dataset into your browser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyodide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyfetch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyodide'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#This function will download the dataset into your browser \n","\n","from pyodide.http import pyfetch\n","\n","async def download(url, filename):\n","    response = await pyfetch(url)\n","    if response.status == 200:\n","        with open(filename, \"wb\") as f:\n","            f.write(await response.bytes())"]},{"cell_type":"markdown","metadata":{"id":"P72cpSE3r8Mp"},"source":["<h2>Read Data</h2>\n","<p>\n","We use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n","\n","Because the data does not include headers, we can add an argument <code>headers = None</code> inside the <code>read_csv()</code> method so that pandas will not automatically set the first row as a header.<br>\n","\n","You can also assign the dataset to any variable you create.\n","\n","</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1bddgskr8Mq"},"outputs":[],"source":["path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""]},{"cell_type":"markdown","metadata":{"id":"FNHve-Uhr8Mq"},"source":["you will need to download the dataset; if you are running locally, please comment out the following\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTfLzRN-r8Mr"},"outputs":[],"source":["#you will need to download the dataset; if you are running locally, please comment out the following \n","await download(path, \"auto.csv\")\n","path=\"auto.csv\""]},{"cell_type":"markdown","metadata":{"id":"fLiDaxosr8Mr"},"source":["This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZDGwEI3r8Ms"},"outputs":[],"source":["# Import pandas library\n","import pandas as pd\n","\n","# Read the online file by the URL provides above, and assign it to variable \"df\"\n","\n","df = pd.read_csv(path, header=None)"]},{"cell_type":"markdown","metadata":{"id":"o80tKGN2r8Ms"},"source":["After reading the dataset, we can use the <code>dataframe.head(n)</code> method to check the top n rows of the dataframe, where n is an integer. Contrary to <code>dataframe.head(n)</code>, <code>dataframe.tail(n)</code> will show you the bottom n rows of the dataframe.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLXHJMvBr8Ms"},"outputs":[],"source":["# show the first 5 rows using dataframe.head() method\n","print(\"The first 5 rows of the dataframe\") \n","df.head(5)"]},{"cell_type":"markdown","metadata":{"id":"jxH-s1zQr8Ms"},"source":["<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n","<h1> Question #1: </h1>\n","<b>Check the bottom 10 rows of data frame \"df\".</b>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muC7eJoqr8Mt"},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","metadata":{"id":"JxPsuW5Mr8Mt"},"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","print(\"The last 10 rows of the dataframe\\n\")\n","df.tail(10)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"MkZM2w5cr8Mt"},"source":["<h3>Add Headers</h3>\n","<p>\n","Take a look at our dataset. Pandas automatically set the header with an integer starting from 0.\n","</p>\n","<p>\n","To better describe our data, we can introduce a header. This information is available at:  <a href=\"https://archive.ics.uci.edu/ml/datasets/Automobile?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Automobile</a>.\n","</p>\n","<p>\n","Thus, we have to add headers manually.\n","</p>\n","<p>\n","First, we create a list \"headers\" that include all column names in order.\n","Then, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n","</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fqkqqw4cr8Mt"},"outputs":[],"source":["# create headers list\n","headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n","         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n","         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n","         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n","print(\"headers\\n\", headers)"]},{"cell_type":"markdown","metadata":{"id":"MNMlGW0ir8Mu"},"source":["We replace headers and recheck our dataframe:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywXU3t_fr8Mu"},"outputs":[],"source":["df.columns = headers\n","df.head(10)"]},{"cell_type":"markdown","metadata":{"id":"S0vz88a_r8Mu"},"source":["We need to replace the \"?\" symbol with NaN so the dropna() can remove the missing values:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1J_X1mKTr8Mu"},"outputs":[],"source":["df1=df.replace('?',np.NaN)\n"]},{"cell_type":"markdown","metadata":{"id":"UIhnUJ0pr8Mv"},"source":["We can drop missing values along the column \"price\" as follows:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ip35ZKegr8Mv"},"outputs":[],"source":["df=df1.dropna(subset=[\"price\"], axis=0)\n","df.head(20)"]},{"cell_type":"markdown","metadata":{"id":"gF228f4Qr8Mv"},"source":["Now, we have successfully read the raw dataset and added the correct headers into the dataframe.\n"]},{"cell_type":"markdown","metadata":{"id":"TUgcxbPUr8Mv"},"source":[" <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n","<h1> Question #2: </h1>\n","<b>Find the name of the columns of the dataframe.</b>\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ovP9_f3r8Mv"},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","metadata":{"id":"dupiAjIAr8Mv"},"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","print(df.columns)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"id":"CIlAvFlWr8Mw"},"source":["<h2>Save Dataset</h2>\n","<p>\n","Correspondingly, Pandas enables us to save the dataset to csv. By using the <code>dataframe.to_csv()</code> method, you can add the file path and name along with quotation marks in the brackets.\n","</p>\n","<p>\n","For example, if you would save the dataframe <b>df</b> as <b>automobile.csv</b> to your local machine, you may use the syntax below, where <code>index = False</code> means the row names will not be written.\n","</p>\n"]},{"cell_type":"raw","metadata":{"id":"zFT075e6r8Mw"},"source":["df.to_csv(\"automobile.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"A25vqcTSr8Mw"},"source":["We can also read and save other file formats. We can use similar functions like **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"]},{"cell_type":"markdown","metadata":{"id":"lOC53Dmxr8Mw"},"source":["<h2>Read/Save Other Data Formats</h2>\n","\n","| Data Formate |        Read       |            Save |\n","| ------------ | :---------------: | --------------: |\n","| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n","| json         |  `pd.read_json()` |  `df.to_json()` |\n","| excel        | `pd.read_excel()` | `df.to_excel()` |\n","| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n","| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n","| ...          |        ...        |             ... |\n"]},{"cell_type":"markdown","metadata":{"id":"vzVc6dnur8Mw"},"source":["<h1 id=\"basic_insight\">Basic Insight of Dataset</h1>\n","<p>\n","After reading data into Pandas dataframe, it is time for us to explore the dataset.<br>\n","\n","There are several ways to obtain essential insights of the data to help us better understand our dataset.\n","\n","</p>\n"]},{"cell_type":"markdown","metadata":{"id":"eAG3N7JNr8Mx"},"source":["<h2>Data Types</h2>\n","<p>\n","Data has a variety of types.<br>\n","\n","The main types stored in Pandas dataframes are <b>object</b>, <b>float</b>, <b>int</b>, <b>bool</b> and <b>datetime64</b>. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas:\n","\n","</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vt-jlDHrr8Mx"},"outputs":[],"source":["df.dtypes\n"]},{"cell_type":"markdown","metadata":{"id":"6a0YGwr0r8Mx"},"source":["A series with the data type of each column is returned.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otMi9OYwr8Mx"},"outputs":[],"source":["# check the data type of data frame \"df\" by .dtypes\n","print(df.dtypes)"]},{"cell_type":"markdown","metadata":{"id":"uiN9lMJ2r8My"},"source":["<p>\n","As shown above, it is clear to see that the data type of \"symboling\" and \"curb-weight\" are <code>int64</code>, \"normalized-losses\" is <code>object</code>, and \"wheel-base\" is <code>float64</code>, etc.\n","</p>\n","<p>\n","These data types can be changed; we will learn how to accomplish this in a later module.\n","</p>\n"]},{"cell_type":"markdown","metadata":{"id":"5sY7fpTbr8My"},"source":["<h2>Describe</h2>\n","If we would like to get a statistical summary of each column e.g. count, column mean value, column standard deviation, etc., we use the describe method:\n"]},{"cell_type":"raw","metadata":{"id":"3Ro26aLdr8My"},"source":["dataframe.describe()"]},{"cell_type":"markdown","metadata":{"id":"Z3WoKeWTr8My"},"source":["This method will provide various summary statistics, excluding <code>NaN</code> (Not a Number) values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXGrBxRnr8Mz"},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","metadata":{"id":"8UKMwVaWr8Mz"},"source":["<p>\n","This shows the statistical summary of all numeric-typed (int, float) columns.<br>\n","\n","For example, the attribute \"symboling\" has 205 counts, the mean value of this column is 0.83, the standard deviation is 1.25, the minimum value is -2, 25th percentile is 0, 50th percentile is 1, 75th percentile is 2, and the maximum value is 3. <br>\n","\n","However, what if we would also like to check all the columns including those that are of type object? <br><br>\n","\n","You can add an argument <code>include = \"all\"</code> inside the bracket. Let's try it again.\n","\n","</p>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYtd5caRr8M0"},"outputs":[],"source":["# describe all the columns in \"df\" \n","df.describe(include = \"all\")"]},{"cell_type":"markdown","metadata":{"id":"wPol9-wJr8M0"},"source":["<p>\n","Now it provides the statistical summary of all the columns, including object-typed attributes.<br>\n","\n","We can now see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns.<br>\n","\n","Some values in the table above show as \"NaN\". This is because those numbers are not available regarding a particular column type.<br>\n","\n","</p>\n"]},{"cell_type":"markdown","metadata":{"id":"MVJ2Rhumr8M0"},"source":["<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n","<h1> Question #3: </h1>\n","\n","<p>\n","You can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n","</p>\n","<p>\n","    <code>dataframe[[' column 1 ',column 2', 'column 3']]</code>\n","</p>\n","<p>\n","Where \"column\" is the name of the column, you can apply the method  \".describe()\" to get the statistics of those columns as follows:\n","</p>\n","<p>\n","    <code>dataframe[[' column 1 ',column 2', 'column 3'] ].describe()</code>\n","</p>\n","\n","Apply the  method to \".describe()\" to the columns 'length' and 'compression-ratio'.\n","\n","</div>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QYSIcjor8M1"},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n"]},{"cell_type":"markdown","metadata":{"id":"JAKXmGh-r8M1"},"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","df[['length', 'compression-ratio']].describe()\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"id":"b20twph5r8M2"},"source":["<h2>Info</h2>\n","Another method you can use to check your dataset is:\n"]},{"cell_type":"raw","metadata":{"id":"uikXwIWPr8M2"},"source":["dataframe.info()"]},{"cell_type":"markdown","metadata":{"id":"BcyPl7Ohr8M2"},"source":["It provides a concise summary of your DataFrame.\n","\n","This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Lpp612tr8M3"},"outputs":[],"source":["# look at the info of \"df\"\n","df.info()"]},{"cell_type":"markdown","metadata":{"id":"izy616shr8M3"},"source":["<h1>Excellent! You have just completed the  Introduction Notebook!</h1>\n"]},{"cell_type":"markdown","metadata":{"id":"iQqa56vEr8M3"},"source":["### Thank you for completing this lab!\n","\n","## Author\n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">Joseph Santarcangelo</a>\n","\n","### Other Contributors\n","\n","<a href=\"https://www.linkedin.com/in/mahdi-noorian-58219234/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">Mahdi Noorian PhD</a>\n","\n","Bahare Talayian\n","\n","Eric Xiao\n","\n","Steven Dong\n","\n","Parizad\n","\n","Hima Vasudevan\n","\n","<a href=\"https://www.linkedin.com/in/fiorellawever/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">Fiorella Wenver</a>\n","\n","<a href=\"https:// https://www.linkedin.com/in/yi-leng-yao-84451275/ \" target=\"_blank\" >Yi Yao</a>.\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                         |\n","| ----------------- | ------- | ---------- | ---------------------------------------------------------- |\n","| 2022-08-23        | 2.4     | Malika     | Import micropip added and parameter for ipwidgets and tqdm |\n","| 2020-10-30        | 2.3     | Lakshmi    | Changed URL of the csv                                     |\n","| 2020-09-22        | 2.2     | Nayef      | Added replace() method to remove '?'                       |\n","| 2020-09-09        | 2.1     | Lakshmi    | Made changes in info method of dataframe                   |\n","| 2020-08-27        | 2.0     | Lavanya    | Moved lab to course repo in GitLab                         |\n","\n","<hr>\n","\n","## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}